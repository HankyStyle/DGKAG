{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 fine-tune 過後的 Sentence Transformer 來 rerank triplet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  6 09:15:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 40%   44C    P0    66W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 35%   39C    P0    55W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, sys\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(item):\n",
    "    path = '../../../../data/sciq/{}.with.triplet.json'.format(item)\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data('train')\n",
    "valid = read_data('valid')\n",
    "test = read_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compounds that are capable of accepting electrons, such as o 2 or f2, are called what?\n",
      "['antioxidants', 'Oxygen', 'residues']\n",
      "oxidants\n"
     ]
    }
   ],
   "source": [
    "print(test[0]['sentence'])\n",
    "print(test[0]['distractors'])\n",
    "print(test[0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relatedto', 'oxidants', 'oxidant', 0.6359457969665527],\n",
       " ['relatedto', 'electrons', 'electron', 0.46036529541015625],\n",
       " ['relatedto', 'delocalized', 'electron', 0.43334996700286865],\n",
       " ['relatedto', 'redox', 'electron', 0.43334996700286865],\n",
       " ['relatedto', 'proton', 'electron', 0.43334996700286865],\n",
       " ['relatedto', 'electron', 'proton', 0.43334996700286865],\n",
       " ['relatedto', 'delocalized', 'compound', 0.32832592725753784],\n",
       " ['relatedto', 'called', 'call', -0.034704722464084625]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]['triplets'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation Name Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Relation_Dict ={\n",
    " 'antonym': 'is the antonym of',\n",
    " 'atlocation' : 'is at location of',\n",
    " 'capableof': 'is capable of',\n",
    " 'causes' : 'causes',\n",
    " 'createdby': 'is created by',\n",
    " 'desires': 'desires',\n",
    " 'hasproperty': 'has property',\n",
    " 'hassubevent': 'has subevent',\n",
    " 'isa':'is a kind of',\n",
    " 'madeof':'is made of',\n",
    " 'notcapableof':'has not capable of',\n",
    " 'notdesires': \"does not desires\",\n",
    " 'partof':'is part of',\n",
    " 'receivesaction':'is',\n",
    " 'relatedto':'is related to',\n",
    " 'usedfor':'is used for'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(data):\n",
    "    \n",
    "    sentences = []\n",
    "    triplets = []\n",
    "    labels = []\n",
    "    answers = []\n",
    "    for d in data:\n",
    "        sentence = d['sentence']\n",
    "        distractors = d['distractors']\n",
    "        answer = d['answer']\n",
    "        triplet = d['triplets']\n",
    "\n",
    "\n",
    "        distractors = [dis.strip() for dis in distractors]\n",
    "        sentence = sentence + ' ' +answer\n",
    "\n",
    "        \n",
    "        for each_triplet in triplet:\n",
    "            rel, source, target, weight = each_triplet\n",
    "\n",
    "            sentences.append(sentence)\n",
    "            triplets.append('{} {} {}'.format(source,Relation_Dict[rel],target))\n",
    "\n",
    "            if source == answer or target == answer or source in distractors or target in distractors:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "            \n",
    "    return sentences, triplets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent, train_triplet, train_label = processData(train)\n",
    "valid_sent, valid_triplet, valid_label = processData(valid)\n",
    "test_sent, test_triplet, test_label = processData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260474, 22596, 22403)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sent), len(valid_sent), len(test_sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "統計訓練與測試資料分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 資料分布 : Positive 有 39688 筆, Negative 有 220786 筆，大約有 15.24% 為 Positive。\n",
      "Valid 資料分布 : Positive 有 3147 筆, Negative 有 19449 筆，大約有 13.93% 為 Positive。\n",
      "Test 資料分布 : Positive 有 3499 筆, Negative 有 18904 筆，大約有 15.62% 為 Positive。\n"
     ]
    }
   ],
   "source": [
    "print('Train 資料分布 : Positive 有 {} 筆, Negative 有 {} 筆，大約有 {:.2f}% 為 Positive。'.format(train_label.count(0),train_label.count(1),train_label.count(0)/len(train_sent)*100))\n",
    "print('Valid 資料分布 : Positive 有 {} 筆, Negative 有 {} 筆，大約有 {:.2f}% 為 Positive。'.format(valid_label.count(0),valid_label.count(1),valid_label.count(0)/len(valid_sent)*100))\n",
    "print('Test 資料分布 : Positive 有 {} 筆, Negative 有 {} 筆，大約有 {:.2f}% 為 Positive。'.format(test_label.count(0),test_label.count(1),test_label.count(0)/len(test_sent)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 15:28:50.095521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-08 15:28:50.200589: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-08 15:28:50.750973: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-08 15:28:50.751124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-08 15:28:50.751131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./saved_models/sentence-transformer-sciq-all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_sent, train_triplet, truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(valid_sent, valid_triplet, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_sent, test_triplet, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(encodings, label):\n",
    "    encodings.update({'labels': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_labels(train_encodings, train_label)\n",
    "add_labels(valid_encodings, valid_label)\n",
    "add_labels(test_encodings, test_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義 Dataset，並轉換成 tensor 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, encodings):\n",
    "    self.encodings = encodings\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = Dataset(train_encodings)\n",
    "valid_dataset = Dataset(valid_encodings)\n",
    "test_dataset = Dataset(test_encodings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mpnet to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./saved_models/sentence-transformer-sciq-all/ were not used when initializing BertForSequenceClassification: ['mpnet.encoder.layer.10.output.dense.weight', 'mpnet.encoder.layer.7.attention.attn.q.weight', 'mpnet.encoder.layer.8.attention.LayerNorm.weight', 'mpnet.encoder.layer.5.intermediate.dense.weight', 'mpnet.encoder.layer.11.attention.attn.v.weight', 'mpnet.encoder.layer.4.attention.LayerNorm.weight', 'mpnet.encoder.layer.10.attention.attn.k.weight', 'mpnet.encoder.layer.9.output.dense.bias', 'mpnet.encoder.layer.5.attention.attn.v.weight', 'mpnet.encoder.layer.4.output.dense.bias', 'mpnet.encoder.layer.3.attention.attn.k.bias', 'mpnet.encoder.layer.5.output.LayerNorm.bias', 'mpnet.encoder.layer.7.output.dense.weight', 'mpnet.encoder.layer.2.attention.LayerNorm.bias', 'mpnet.encoder.layer.3.attention.attn.k.weight', 'mpnet.encoder.layer.6.output.LayerNorm.bias', 'mpnet.encoder.layer.6.attention.attn.q.weight', 'mpnet.encoder.layer.10.attention.attn.o.weight', 'mpnet.encoder.layer.5.attention.attn.k.weight', 'classifier.dense.weight', 'mpnet.encoder.layer.11.attention.attn.q.weight', 'mpnet.encoder.layer.8.intermediate.dense.weight', 'mpnet.encoder.layer.3.intermediate.dense.bias', 'mpnet.encoder.layer.2.attention.attn.o.bias', 'mpnet.encoder.layer.3.output.LayerNorm.weight', 'mpnet.encoder.layer.8.attention.attn.v.weight', 'mpnet.encoder.layer.1.attention.attn.o.bias', 'mpnet.encoder.layer.4.attention.attn.q.bias', 'mpnet.encoder.layer.3.attention.attn.o.weight', 'mpnet.encoder.layer.2.attention.attn.q.weight', 'mpnet.encoder.layer.10.attention.attn.v.bias', 'mpnet.encoder.layer.5.attention.attn.q.bias', 'mpnet.encoder.layer.4.output.LayerNorm.bias', 'mpnet.encoder.layer.6.attention.LayerNorm.bias', 'mpnet.encoder.layer.10.attention.attn.q.bias', 'mpnet.encoder.layer.7.attention.attn.v.bias', 'mpnet.encoder.layer.0.attention.attn.k.bias', 'mpnet.encoder.layer.8.attention.LayerNorm.bias', 'mpnet.encoder.layer.8.output.dense.bias', 'mpnet.encoder.layer.8.output.LayerNorm.weight', 'mpnet.encoder.layer.11.attention.attn.k.weight', 'mpnet.embeddings.LayerNorm.bias', 'mpnet.encoder.layer.4.attention.LayerNorm.bias', 'mpnet.encoder.layer.9.attention.attn.v.bias', 'mpnet.encoder.layer.2.output.LayerNorm.weight', 'mpnet.encoder.layer.11.attention.LayerNorm.bias', 'classifier.dense.bias', 'mpnet.encoder.layer.9.attention.LayerNorm.weight', 'mpnet.encoder.layer.5.output.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'mpnet.encoder.layer.6.output.LayerNorm.weight', 'mpnet.encoder.layer.5.attention.LayerNorm.weight', 'mpnet.encoder.layer.5.output.LayerNorm.weight', 'mpnet.encoder.layer.5.attention.attn.o.bias', 'mpnet.encoder.layer.0.output.LayerNorm.weight', 'mpnet.encoder.layer.0.output.LayerNorm.bias', 'mpnet.encoder.layer.8.attention.attn.o.bias', 'mpnet.encoder.layer.6.attention.attn.k.bias', 'mpnet.encoder.layer.0.intermediate.dense.weight', 'mpnet.encoder.layer.4.intermediate.dense.bias', 'mpnet.encoder.layer.1.attention.attn.k.weight', 'mpnet.encoder.layer.4.attention.attn.v.bias', 'mpnet.encoder.layer.7.output.LayerNorm.bias', 'mpnet.encoder.layer.11.attention.attn.o.bias', 'mpnet.encoder.layer.3.attention.attn.q.bias', 'mpnet.encoder.layer.9.attention.attn.v.weight', 'mpnet.encoder.layer.10.intermediate.dense.bias', 'mpnet.encoder.layer.4.attention.attn.o.bias', 'mpnet.encoder.layer.8.attention.attn.q.bias', 'mpnet.encoder.layer.9.attention.attn.o.weight', 'mpnet.encoder.layer.9.intermediate.dense.weight', 'mpnet.encoder.layer.10.output.LayerNorm.weight', 'mpnet.encoder.layer.10.attention.attn.v.weight', 'mpnet.encoder.layer.11.attention.attn.q.bias', 'mpnet.encoder.layer.11.attention.LayerNorm.weight', 'mpnet.encoder.layer.2.intermediate.dense.bias', 'mpnet.encoder.layer.9.output.LayerNorm.weight', 'mpnet.encoder.layer.8.intermediate.dense.bias', 'mpnet.encoder.layer.7.attention.attn.o.bias', 'mpnet.encoder.layer.3.output.LayerNorm.bias', 'mpnet.encoder.layer.2.attention.LayerNorm.weight', 'mpnet.encoder.layer.0.output.dense.bias', 'mpnet.encoder.layer.8.output.LayerNorm.bias', 'mpnet.encoder.layer.3.attention.LayerNorm.weight', 'mpnet.encoder.layer.2.attention.attn.v.weight', 'mpnet.encoder.layer.0.attention.LayerNorm.weight', 'mpnet.encoder.layer.0.attention.attn.v.weight', 'mpnet.encoder.layer.2.intermediate.dense.weight', 'mpnet.encoder.layer.10.intermediate.dense.weight', 'mpnet.encoder.layer.2.output.LayerNorm.bias', 'mpnet.encoder.layer.1.attention.LayerNorm.weight', 'mpnet.encoder.layer.11.attention.attn.v.bias', 'mpnet.encoder.layer.0.attention.attn.o.weight', 'mpnet.encoder.layer.6.attention.attn.v.bias', 'mpnet.encoder.layer.3.output.dense.weight', 'mpnet.encoder.layer.4.output.dense.weight', 'mpnet.encoder.layer.9.attention.attn.q.weight', 'mpnet.encoder.layer.9.attention.attn.o.bias', 'mpnet.encoder.layer.4.attention.attn.q.weight', 'mpnet.embeddings.LayerNorm.weight', 'mpnet.encoder.layer.3.attention.attn.v.weight', 'mpnet.encoder.layer.5.output.dense.bias', 'mpnet.encoder.layer.8.attention.attn.v.bias', 'mpnet.encoder.layer.4.attention.attn.k.bias', 'mpnet.encoder.layer.3.attention.attn.v.bias', 'mpnet.encoder.layer.2.output.dense.bias', 'mpnet.encoder.layer.5.attention.attn.q.weight', 'mpnet.encoder.layer.1.intermediate.dense.bias', 'mpnet.embeddings.word_embeddings.weight', 'mpnet.encoder.layer.8.attention.attn.o.weight', 'mpnet.encoder.layer.10.attention.LayerNorm.weight', 'mpnet.encoder.layer.4.attention.attn.v.weight', 'mpnet.encoder.layer.8.attention.attn.k.bias', 'mpnet.encoder.layer.1.output.LayerNorm.weight', 'mpnet.encoder.layer.2.output.dense.weight', 'mpnet.encoder.layer.1.output.LayerNorm.bias', 'mpnet.encoder.layer.7.intermediate.dense.weight', 'mpnet.encoder.layer.7.intermediate.dense.bias', 'mpnet.encoder.layer.7.output.LayerNorm.weight', 'mpnet.encoder.layer.11.output.LayerNorm.bias', 'mpnet.encoder.layer.11.attention.attn.o.weight', 'mpnet.encoder.layer.0.attention.attn.v.bias', 'mpnet.encoder.layer.7.attention.LayerNorm.bias', 'mpnet.encoder.layer.1.attention.attn.q.bias', 'mpnet.encoder.layer.6.attention.attn.q.bias', 'mpnet.encoder.layer.10.attention.attn.k.bias', 'mpnet.encoder.relative_attention_bias.weight', 'mpnet.encoder.layer.11.output.LayerNorm.weight', 'mpnet.encoder.layer.4.intermediate.dense.weight', 'mpnet.encoder.layer.7.attention.attn.q.bias', 'mpnet.encoder.layer.1.output.dense.bias', 'mpnet.encoder.layer.0.attention.attn.q.weight', 'mpnet.encoder.layer.6.attention.attn.k.weight', 'mpnet.encoder.layer.9.attention.attn.q.bias', 'mpnet.encoder.layer.8.output.dense.weight', 'mpnet.encoder.layer.6.intermediate.dense.bias', 'mpnet.encoder.layer.11.intermediate.dense.weight', 'mpnet.encoder.layer.4.attention.attn.o.weight', 'mpnet.encoder.layer.1.intermediate.dense.weight', 'mpnet.encoder.layer.2.attention.attn.k.weight', 'mpnet.encoder.layer.11.intermediate.dense.bias', 'mpnet.embeddings.position_ids', 'mpnet.encoder.layer.11.output.dense.bias', 'mpnet.encoder.layer.5.attention.attn.v.bias', 'mpnet.encoder.layer.11.output.dense.weight', 'mpnet.encoder.layer.9.attention.LayerNorm.bias', 'mpnet.encoder.layer.0.output.dense.weight', 'mpnet.encoder.layer.3.attention.LayerNorm.bias', 'mpnet.encoder.layer.10.attention.LayerNorm.bias', 'mpnet.encoder.layer.5.attention.attn.k.bias', 'mpnet.encoder.layer.2.attention.attn.v.bias', 'mpnet.encoder.layer.5.intermediate.dense.bias', 'mpnet.encoder.layer.2.attention.attn.o.weight', 'mpnet.encoder.layer.0.intermediate.dense.bias', 'mpnet.encoder.layer.6.intermediate.dense.weight', 'mpnet.encoder.layer.1.attention.LayerNorm.bias', 'mpnet.encoder.layer.6.attention.LayerNorm.weight', 'mpnet.encoder.layer.6.output.dense.weight', 'mpnet.encoder.layer.0.attention.LayerNorm.bias', 'mpnet.encoder.layer.0.attention.attn.q.bias', 'mpnet.encoder.layer.1.attention.attn.q.weight', 'mpnet.encoder.layer.1.attention.attn.v.bias', 'mpnet.encoder.layer.8.attention.attn.k.weight', 'mpnet.encoder.layer.10.output.dense.bias', 'mpnet.encoder.layer.2.attention.attn.q.bias', 'mpnet.encoder.layer.1.output.dense.weight', 'mpnet.encoder.layer.7.attention.attn.k.weight', 'mpnet.encoder.layer.2.attention.attn.k.bias', 'mpnet.encoder.layer.9.attention.attn.k.bias', 'mpnet.encoder.layer.9.output.dense.weight', 'mpnet.encoder.layer.1.attention.attn.v.weight', 'mpnet.encoder.layer.5.attention.LayerNorm.bias', 'mpnet.encoder.layer.4.attention.attn.k.weight', 'mpnet.encoder.layer.1.attention.attn.o.weight', 'mpnet.encoder.layer.7.attention.attn.o.weight', 'mpnet.encoder.layer.6.attention.attn.o.bias', 'mpnet.encoder.layer.7.attention.LayerNorm.weight', 'mpnet.encoder.layer.9.intermediate.dense.bias', 'mpnet.encoder.layer.7.attention.attn.v.weight', 'mpnet.encoder.layer.9.output.LayerNorm.bias', 'mpnet.encoder.layer.5.attention.attn.o.weight', 'mpnet.encoder.layer.3.attention.attn.o.bias', 'mpnet.encoder.layer.6.attention.attn.v.weight', 'mpnet.encoder.layer.7.attention.attn.k.bias', 'mpnet.encoder.layer.6.attention.attn.o.weight', 'mpnet.encoder.layer.3.output.dense.bias', 'mpnet.embeddings.position_embeddings.weight', 'mpnet.encoder.layer.3.attention.attn.q.weight', 'mpnet.encoder.layer.6.output.dense.bias', 'mpnet.encoder.layer.1.attention.attn.k.bias', 'mpnet.encoder.layer.9.attention.attn.k.weight', 'mpnet.encoder.layer.4.output.LayerNorm.weight', 'mpnet.encoder.layer.0.attention.attn.o.bias', 'mpnet.encoder.layer.7.output.dense.bias', 'mpnet.encoder.layer.10.attention.attn.q.weight', 'mpnet.encoder.layer.0.attention.attn.k.weight', 'mpnet.encoder.layer.3.intermediate.dense.weight', 'mpnet.encoder.layer.10.output.LayerNorm.bias', 'mpnet.encoder.layer.11.attention.attn.k.bias', 'mpnet.encoder.layer.8.attention.attn.q.weight', 'mpnet.encoder.layer.10.attention.attn.o.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./saved_models/sentence-transformer-sciq-all/ and are newly initialized: ['encoder.layer.9.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'classifier.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'classifier.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "config  = BertConfig.from_pretrained('./saved_models/sentence-transformer-sciq-all/', num_labels = 2) # num_labels 設定類別數\n",
    "model = BertForSequenceClassification.from_pretrained('./saved_models/sentence-transformer-sciq-all/', config=config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "   \n",
    "    results = metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {'accuracy': results['accuracy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    save_strategy = \"epoch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    weight_decay=0.01,\n",
    "    eval_accumulation_steps = 1,\n",
    "    report_to=\"wandb\" if os.getenv(\"WANDB_PROJECT\") else \"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 22403\n",
      "  Batch size = 64\n",
      "You're using a MPNetTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.7386144399642944,\n",
       " 'test_accuracy': 0.15636298709994198,\n",
       " 'test_runtime': 23.5301,\n",
       " 'test_samples_per_second': 952.101,\n",
       " 'test_steps_per_second': 14.917}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(test_dataset)\n",
    "print('test: ')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06555603, -0.13582139], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions, axis=-1)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(test_sent[0],test_triplet[0], truncation=True, padding=True, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model_output, axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerank Sciq Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_data(data, predictions):\n",
    "    idx = 0\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    for d in data:\n",
    "        for each_triplet in d['triplets']:\n",
    "            rel, source, target, weight = each_triplet\n",
    "\n",
    "            if predictions[idx] == 0:\n",
    "                each_triplet[3] += 1.0\n",
    "\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03046609, -0.21285811],\n",
       "       [ 0.0301279 , -0.2142671 ],\n",
       "       [ 0.01066719, -0.20922351],\n",
       "       ...,\n",
       "       [-0.03168179, -0.22601952],\n",
       "       [-0.04911616, -0.24205561],\n",
       "       [-0.04201736, -0.24933326]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22403"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_data(test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../../../data/sciq/test.with.reranker.triplet.json'\n",
    "jsonString = json.dumps(test)\n",
    "jsonFile = open(file_path, \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 260474\n",
      "  Batch size = 64\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.7391087412834167,\n",
       " 'test_accuracy': 0.1530671007470995,\n",
       " 'test_runtime': 387.8461,\n",
       " 'test_samples_per_second': 671.591,\n",
       " 'test_steps_per_second': 10.494}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(train_dataset)\n",
    "print('train: ')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_data(train,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../../../data/sciq/train.with.reranker.triplet.json'\n",
    "jsonString = json.dumps(train)\n",
    "jsonFile = open(file_path, \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 22596\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.7401852607727051,\n",
       " 'test_accuracy': 0.14099840679766332,\n",
       " 'test_runtime': 24.8018,\n",
       " 'test_samples_per_second': 911.063,\n",
       " 'test_steps_per_second': 14.273}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(valid_dataset)\n",
    "print('valid: ')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_data(valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../../../data/sciq/valid.with.reranker.triplet.json'\n",
    "jsonString = json.dumps(valid)\n",
    "jsonFile = open(file_path, \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
