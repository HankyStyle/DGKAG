{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert MCQ Dataset to Grounded Type (Original Data with Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import nltk\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import uuid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords', quiet=True)\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_file = './data/mcq/total_new_cleaned_train.json'\n",
    "output_file = './data/mcq/grounded/train.grounded.json'\n",
    "CPNET_VOCAB = './data/cpnet/concept.txt'\n",
    "PATTERN_PATH = './data/cpnet/matcher_patterns.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dg_file, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace **blank** with distractor in statment and label false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data:\n",
    "    statements = []\n",
    "\n",
    "    sentence_text = item['sentence']\n",
    "    distractors = item['distractors']\n",
    "    answer_text = item['answer']\n",
    "\n",
    "    stem = sentence_text.replace('**blank**',answer_text)\n",
    "    statements.append({'label':True,'stem':stem})\n",
    "    for distractor in distractors:\n",
    "        stem = sentence_text.replace('**blank**',distractor)\n",
    "        statements.append({'label':False,'stem':stem})\n",
    "    item['statements'] = statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'gravity',\n",
       " 'distractors': ['friction', 'erosion', 'magnetism'],\n",
       " 'sentence': '**blank** causes rocks to roll downhill',\n",
       " 'statements': [{'label': True,\n",
       "   'stem': 'gravity causes rocks to roll downhill'},\n",
       "  {'label': False, 'stem': 'friction causes rocks to roll downhill'},\n",
       "  {'label': False, 'stem': 'erosion causes rocks to roll downhill'},\n",
       "  {'label': False, 'stem': 'magnetism causes rocks to roll downhill'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = None\n",
    "matcher = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpnet_vocab(cpnet_vocab_path):\n",
    "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
    "        cpnet_vocab = [l.strip() for l in fin]\n",
    "    cpnet_vocab = [c.replace(\"_\", \" \") for c in cpnet_vocab]\n",
    "    return cpnet_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global PATTERN_PATH, CPNET_VOCAB\n",
    "if PATTERN_PATH is None:\n",
    "    PATTERN_PATH = pattern_path\n",
    "    CPNET_VOCAB = load_cpnet_vocab(cpnet_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "answers = []\n",
    "distractors = []\n",
    "\n",
    "for item in data:\n",
    "\n",
    "    sentence_text = item['sentence']\n",
    "    distractors_list = item['distractors']\n",
    "    answer_text = item['answer']\n",
    "\n",
    "    statement = sentence_text.replace('**blank**',answer_text)\n",
    "    sents.append(statement)\n",
    "    answers.append(answer_text)\n",
    "    distractors.append(distractors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gravity causes rocks to roll downhill\n",
      "gravity\n",
      "['friction', 'erosion', 'magnetism']\n"
     ]
    }
   ],
   "source": [
    "print(sents[0])\n",
    "print(answers[0])\n",
    "print(distractors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2321\n"
     ]
    }
   ],
   "source": [
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2321\n"
     ]
    }
   ],
   "source": [
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2321\n"
     ]
    }
   ],
   "source": [
    "print(len(distractors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the entity in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(nlp, concept):\n",
    "    doc = nlp(concept.replace(\"_\", \" \"))\n",
    "    lcs = set()\n",
    "    lcs.add(\"_\".join([token.lemma_ for token in doc]))  # all lemma\n",
    "    return lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_qa_pair(qa_pair):\n",
    "    global nlp, matcher\n",
    "    if nlp is None or matcher is None:\n",
    "        nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'textcat'])\n",
    "        nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "        matcher = load_matcher(nlp, PATTERN_PATH)\n",
    "\n",
    "    s, a = qa_pair\n",
    "    all_concepts = ground_mentioned_concepts(nlp, matcher, s, a)\n",
    "    answer_concepts = ground_mentioned_concepts(nlp, matcher, a)\n",
    "    question_concepts = all_concepts - answer_concepts\n",
    "    if len(question_concepts) == 0:\n",
    "        question_concepts = hard_ground(nlp, s, CPNET_VOCAB)  # not very possible\n",
    "\n",
    "    if len(answer_concepts) == 0:\n",
    "        answer_concepts = hard_ground(nlp, a, CPNET_VOCAB)  # some case\n",
    "\n",
    "    # question_concepts = question_concepts -  answer_concepts\n",
    "    question_concepts = sorted(list(question_concepts))\n",
    "    answer_concepts = sorted(list(answer_concepts))\n",
    "    return {\"sent\": s, \"ans\": a, \"qc\": question_concepts, \"ac\": answer_concepts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_ground(nlp, sent, cpnet_vocab):\n",
    "    sent = sent.lower()\n",
    "    doc = nlp(sent)\n",
    "    res = set()\n",
    "    for t in doc:\n",
    "        if t.lemma_ in cpnet_vocab:\n",
    "            res.add(t.lemma_)\n",
    "    sent = \" \".join([t.text for t in doc])\n",
    "    if sent in cpnet_vocab:\n",
    "        res.add(sent)\n",
    "    try:\n",
    "        assert len(res) > 0\n",
    "    except Exception:\n",
    "        print(f\"for {sent}, concept not found in hard grounding.\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matcher(nlp, pattern_path):\n",
    "    with open(pattern_path, \"r\", encoding=\"utf8\") as fin:\n",
    "        all_patterns = json.load(fin)\n",
    "\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    for concept, pattern in all_patterns.items():\n",
    "        matcher.add(concept, None, pattern)\n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_mentioned_concepts(nlp, matcher, s, ans=None):\n",
    "\n",
    "    s = s.lower()\n",
    "    doc = nlp(s)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    mentioned_concepts = set()\n",
    "    span_to_concepts = {}\n",
    "\n",
    "    if ans is not None:\n",
    "        ans_matcher = Matcher(nlp.vocab)\n",
    "        ans_words = nlp(ans)\n",
    "        # print(ans_words)\n",
    "        ans_matcher.add(ans, None, [{'TEXT': token.text.lower()} for token in ans_words])\n",
    "\n",
    "        ans_match = ans_matcher(doc)\n",
    "        ans_mentions = set()\n",
    "        for _, ans_start, ans_end in ans_match:\n",
    "            ans_mentions.add((ans_start, ans_end))\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        if ans is not None:\n",
    "            if (start, end) in ans_mentions:\n",
    "                continue\n",
    "\n",
    "        span = doc[start:end].text  # the matched span\n",
    "\n",
    "        # a word that appears in answer is not considered as a mention in the question\n",
    "        # if len(set(span.split(\" \")).intersection(set(ans.split(\" \")))) > 0:\n",
    "        #     continue\n",
    "        original_concept = nlp.vocab.strings[match_id]\n",
    "        original_concept_set = set()\n",
    "        original_concept_set.add(original_concept)\n",
    "\n",
    "        # print(\"span\", span)\n",
    "        # print(\"concept\", original_concept)\n",
    "        # print(\"Matched '\" + span + \"' to the rule '\" + string_id)\n",
    "\n",
    "        # why do you lemmatize a mention whose len == 1?\n",
    "\n",
    "        if len(original_concept.split(\"_\")) == 1:\n",
    "            # tag = doc[start].tag_\n",
    "            # if tag in ['VBN', 'VBG']:\n",
    "\n",
    "            original_concept_set.update(lemmatize(nlp, nlp.vocab.strings[match_id]))\n",
    "\n",
    "        if span not in span_to_concepts:\n",
    "            span_to_concepts[span] = set()\n",
    "\n",
    "        span_to_concepts[span].update(original_concept_set)\n",
    "\n",
    "    for span, concepts in span_to_concepts.items():\n",
    "        concepts_sorted = list(concepts)\n",
    "        # print(\"span:\")\n",
    "        # print(span)\n",
    "        # print(\"concept_sorted:\")\n",
    "        # print(concepts_sorted)\n",
    "        concepts_sorted.sort(key=len)\n",
    "\n",
    "        # mentioned_concepts.update(concepts_sorted[0:2])\n",
    "\n",
    "        shortest = concepts_sorted[0:3]\n",
    "\n",
    "        for c in shortest:\n",
    "            if c in blacklist:\n",
    "                continue\n",
    "\n",
    "            # a set with one string like: set(\"like_apples\")\n",
    "            lcs = lemmatize(nlp, c)\n",
    "            intersect = lcs.intersection(shortest)\n",
    "            if len(intersect) > 0:\n",
    "                mentioned_concepts.add(list(intersect)[0])\n",
    "            else:\n",
    "                mentioned_concepts.add(c)\n",
    "\n",
    "        # if a mention exactly matches with a concept\n",
    "\n",
    "        exact_match = set([concept for concept in concepts_sorted if concept.replace(\"_\", \" \").lower() == span.lower()])\n",
    "        # print(\"exact match:\")\n",
    "        # print(exact_match)\n",
    "        assert len(exact_match) < 2\n",
    "        mentioned_concepts.update(exact_match)\n",
    "\n",
    "    return mentioned_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set([\"-PRON-\", \"actually\", \"likely\", \"possibly\", \"want\",\n",
    "                 \"make\", \"my\", \"someone\", \"sometimes_people\", \"sometimes\", \"would\", \"want_to\",\n",
    "                 \"one\", \"something\", \"sometimes\", \"everybody\", \"somebody\", \"could\", \"could_be\"\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 313/2321 [02:09<16:30,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for co2, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 371/2321 [02:32<12:12,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for co2, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 386/2321 [02:40<16:38,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for cho, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 392/2321 [02:42<11:21,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for gcm3, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 462/2321 [03:09<13:45,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 150, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 463/2321 [03:10<14:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 300, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 464/2321 [03:10<15:33,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 17, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 465/2321 [03:11<18:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 25, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 466/2321 [03:12<18:44,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 125, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 470/2321 [03:14<17:47,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 25,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 472/2321 [03:15<17:46,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 10,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 473/2321 [03:16<17:04,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 40,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 474/2321 [03:16<19:36,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 2,100, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 476/2321 [03:17<15:29,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for p3, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 477/2321 [03:17<12:57,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 7.50, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 478/2321 [03:19<23:24,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 140,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 484/2321 [03:23<23:11,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 90,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 486/2321 [03:24<24:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 1.99, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 487/2321 [03:25<22:18,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2 %, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 489/2321 [03:26<19:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1%-3 %, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 490/2321 [03:26<17:55,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 13,333, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 491/2321 [03:27<19:15,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 100,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 492/2321 [03:28<20:27,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2 %, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 507/2321 [03:35<13:23,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1920s, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 508/2321 [03:36<13:41,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1,500, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 520/2321 [03:39<08:27,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1850s, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 527/2321 [03:42<10:56,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for hyperpluralist, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 529/2321 [03:43<11:29,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 20,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 551/2321 [03:51<09:54,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 4,000,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 558/2321 [03:54<09:14,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1970s, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 560/2321 [03:54<10:27,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 46,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 564/2321 [03:57<13:27,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 10,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 580/2321 [04:03<14:39,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for montesqiueu, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 655/2321 [04:41<11:42,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 15 %, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 661/2321 [04:44<10:55,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ch\\'in, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 663/2321 [04:44<09:35,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 10 %, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 679/2321 [04:50<11:10,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for all, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 687/2321 [04:53<11:17,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for wants, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 791/2321 [05:55<13:57,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for more - for - the - same, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 798/2321 [06:01<20:56,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for more - for - more, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 895/2321 [06:58<12:38,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for preapproach, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 905/2321 [07:03<12:07,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for b2c, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 906/2321 [07:04<12:10,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for c2b, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 918/2321 [07:14<24:22,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for nicher, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 923/2321 [07:17<14:40,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for own, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 1014/2321 [07:57<08:56,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ebbinghaus, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1052/2321 [08:13<07:45,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i d, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1053/2321 [08:14<08:08,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i d, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1084/2321 [08:27<08:53,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for locura, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1101/2321 [08:36<12:09,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pseudo-, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1105/2321 [08:38<09:29,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for maslow, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1182/2321 [09:08<06:21,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for corticalization, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 1193/2321 [09:12<07:28,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pinel, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1219/2321 [09:20<04:24,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1230/2321 [09:22<04:41,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for alektorphobic, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1236/2321 [09:24<04:35,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for u.s, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1240/2321 [09:25<05:27,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1,000, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1256/2321 [09:29<04:16,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for anheuser - busch, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1306/2321 [09:44<05:18,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for one, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1310/2321 [09:45<04:27,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for one, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1316/2321 [09:47<05:19,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for one, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1345/2321 [09:54<03:58,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1970s, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1430/2321 [10:18<03:23,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for silcon, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1577/2321 [10:57<03:17,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for one, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1806/2321 [12:05<01:57,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for glycolsis, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1866/2321 [12:23<02:18,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for one, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1872/2321 [12:25<02:15,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for plasmodesmata, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 2169/2321 [13:58<00:48,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for arcualia, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 2278/2321 [14:33<00:15,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for adaptatioins, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 2302/2321 [14:41<00:05,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for sorroundings, concept not found in hard grounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2321/2321 [14:46<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "res = list(tqdm(map(ground_qa_pair, zip(sents, answers)), total=len(sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': \"meter of measurement describes an object 's length\",\n",
       " 'ans': 'meter',\n",
       " 'qc': ['describe',\n",
       "  'describes',\n",
       "  'length',\n",
       "  'measurement',\n",
       "  'object',\n",
       "  'of_measurement'],\n",
       " 'ac': ['meter']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(data, cpnet_vocab_path):\n",
    "    # reload cpnet_vocab\n",
    "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
    "        cpnet_vocab = [l.strip() for l in fin]\n",
    "\n",
    "    prune_data = []\n",
    "    for item in tqdm(data):\n",
    "        qc = item[\"qc\"]\n",
    "        prune_qc = []\n",
    "        for c in qc:\n",
    "            if c[-2:] == \"er\" and c[:-2] in qc:\n",
    "                continue\n",
    "            if c[-1:] == \"e\" and c[:-1] in qc:\n",
    "                continue\n",
    "            have_stop = False\n",
    "            # remove all concepts having stopwords, including hard-grounded ones\n",
    "            for t in c.split(\"_\"):\n",
    "                if t in nltk_stopwords:\n",
    "                    have_stop = True\n",
    "            if not have_stop and c in cpnet_vocab:\n",
    "                prune_qc.append(c)\n",
    "\n",
    "        ac = item[\"ac\"]\n",
    "        prune_ac = []\n",
    "        for c in ac:\n",
    "            if c[-2:] == \"er\" and c[:-2] in ac:\n",
    "                continue\n",
    "            if c[-1:] == \"e\" and c[:-1] in ac:\n",
    "                continue\n",
    "            all_stop = True\n",
    "            for t in c.split(\"_\"):\n",
    "                if t not in nltk_stopwords:\n",
    "                    all_stop = False\n",
    "            if not all_stop and c in cpnet_vocab:\n",
    "                prune_ac.append(c)\n",
    "\n",
    "        try:\n",
    "            assert len(prune_ac) > 0 and len(prune_qc) > 0\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print(\"In pruning\")\n",
    "            # print(prune_qc)\n",
    "            # print(prune_ac)\n",
    "            # print(\"original:\")\n",
    "            # print(qc)\n",
    "            # print(ac)\n",
    "            # print()\n",
    "        item[\"qc\"] = prune_qc\n",
    "        item[\"ac\"] = prune_ac\n",
    "\n",
    "        prune_data.append(item)\n",
    "    return prune_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpnet_vocab_path = CPNET_VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2321 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nltk_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[39m=\u001b[39m prune(res, cpnet_vocab_path)\n",
      "Cell \u001b[0;32mIn[36], line 18\u001b[0m, in \u001b[0;36mprune\u001b[0;34m(data, cpnet_vocab_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# remove all concepts having stopwords, including hard-grounded ones\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m c\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39min\u001b[39;00m nltk_stopwords:\n\u001b[1;32m     19\u001b[0m         have_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m have_stop \u001b[39mand\u001b[39;00m c \u001b[39min\u001b[39;00m cpnet_vocab:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "res = prune(res, cpnet_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path, 'w') as fout:\n",
    "    for dic in res:\n",
    "        fout.write(json.dumps(dic) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
