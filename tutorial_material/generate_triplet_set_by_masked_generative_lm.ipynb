{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用 ChatGPT 與 MLM 的 Candidate Set 找相關 relevant node 並存成 Triplet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from conceptnet import merged_relations\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from multiprocessing import Pool\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# from .maths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounded_path = '/user_data/dggnn/data/MCQ/grounded/test.grounded.jsonl'\n",
    "cpnet_graph_path = '/user_data/qagnn/data/cpnet/conceptnet.en.pruned.graph'\n",
    "cpnet_vocab_path = '/user_data/qagnn/data/cpnet/concept.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['generate_graph']\n",
    "\n",
    "concept2id = None\n",
    "id2concept = None\n",
    "relation2id = None\n",
    "id2relation = None\n",
    "\n",
    "cpnet = None\n",
    "cpnet_all = None\n",
    "cpnet_simple = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(x is None for x in [concept2id, id2concept, relation2id, id2relation])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入 relation 與 concept token 的字典， relation2id 為 relation 的 id ; concept2id 為 concept 的 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resources(cpnet_vocab_path):\n",
    "    global concept2id, id2concept, relation2id, id2relation\n",
    "\n",
    "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
    "        id2concept = [w.strip() for w in fin]\n",
    "    concept2id = {w: i for i, w in enumerate(id2concept)}\n",
    "\n",
    "    id2relation = merged_relations\n",
    "    relation2id = {r: i for i, r in enumerate(id2relation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 concept 的 graph\n",
    "def load_cpnet(cpnet_graph_path):\n",
    "    global cpnet, cpnet_simple\n",
    "    cpnet = nx.read_gpickle(cpnet_graph_path)\n",
    "    cpnet_simple = nx.Graph()\n",
    "    for u, v, data in cpnet.edges(data=True):\n",
    "        w = data['weight'] if 'weight' in data else 1.0\n",
    "        if cpnet_simple.has_edge(u, v):\n",
    "            cpnet_simple[u][v]['weight'] += w\n",
    "        else:\n",
    "            cpnet_simple.add_edge(u, v, weight=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating adj data for /user_data/dggnn/data/MCQ/grounded/test.grounded.jsonl...\n"
     ]
    }
   ],
   "source": [
    "print(f'generating adj data for {grounded_path}...')\n",
    "\n",
    "global concept2id, id2concept, relation2id, id2relation, cpnet_simple, cpnet\n",
    "# 載入 concept2id, id2relation, relation2id\n",
    "if any(x is None for x in [concept2id, id2concept, relation2id, id2relation]):\n",
    "    load_resources(cpnet_vocab_path)\n",
    "if cpnet is None or cpnet_simple is None:\n",
    "    load_cpnet(cpnet_graph_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看 concept2id 內的東西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ab_extra': 0,\n",
       " 'ab_intra': 1,\n",
       " 'abactinal': 2,\n",
       " 'actinal': 3,\n",
       " 'abandon': 4,\n",
       " 'acquire': 5,\n",
       " 'arrogate': 6,\n",
       " 'embrace': 7,\n",
       " 'engage': 8,\n",
       " 'gain': 9,\n",
       " 'join': 10,\n",
       " 'maintain': 11,\n",
       " 'retain': 12,\n",
       " 'unite': 13,\n",
       " 'abandonment': 14,\n",
       " 'acquisition': 15,\n",
       " 'abapical': 16,\n",
       " 'apical': 17,\n",
       " 'abase': 18,\n",
       " 'exalt': 19,\n",
       " 'extoll': 20,\n",
       " 'abash': 21,\n",
       " 'embolden': 22,\n",
       " 'reassure': 23,\n",
       " 'abate': 24,\n",
       " 'augment': 25,\n",
       " 'abaxial': 26,\n",
       " 'adaxial': 27,\n",
       " 'abbreviate': 28,\n",
       " 'lengthen': 29,\n",
       " 'abderian': 30,\n",
       " 'agelastic': 31,\n",
       " 'abducent': 32,\n",
       " 'adducent': 33,\n",
       " 'abduction': 34,\n",
       " 'adduction': 35,\n",
       " 'abductive': 36,\n",
       " 'deduce': 37,\n",
       " 'abductor': 38,\n",
       " 'abductee': 39,\n",
       " 'adductor': 40,\n",
       " 'abideable': 41,\n",
       " 'insupportable': 42,\n",
       " 'intolerable': 43,\n",
       " 'unabideable': 44,\n",
       " 'unbearable': 45,\n",
       " 'abience': 46,\n",
       " 'adience': 47,\n",
       " 'abient': 48,\n",
       " 'adient': 49,\n",
       " 'ability': 50,\n",
       " 'inability': 51,\n",
       " 'abiogenesis': 52,\n",
       " 'biogenesis': 53,\n",
       " 'transformism': 54,\n",
       " 'abjectly': 55,\n",
       " 'proudly': 56,\n",
       " 'abjugate': 57,\n",
       " 'adjugate': 58,\n",
       " 'able': 59,\n",
       " 'cane': 60,\n",
       " 'cannot': 61,\n",
       " 'disability': 62,\n",
       " 'unable': 63,\n",
       " 'abled': 64,\n",
       " 'disabled': 65,\n",
       " 'abluminal': 66,\n",
       " 'adluminal': 67,\n",
       " 'abnormal': 68,\n",
       " 'normal': 69,\n",
       " 'abnormality': 70,\n",
       " 'normality': 71,\n",
       " 'abolish': 72,\n",
       " 'establish': 73,\n",
       " 'abolition': 74,\n",
       " 'establishment': 75,\n",
       " 'aborad': 76,\n",
       " 'orad': 77,\n",
       " 'abortionist': 78,\n",
       " 'anti_abortionist': 79,\n",
       " 'about': 80,\n",
       " 'precisely': 81,\n",
       " 'above': 82,\n",
       " 'below': 83,\n",
       " 'above_average': 84,\n",
       " 'below_average': 85,\n",
       " 'above_fold': 86,\n",
       " 'below_fold': 87,\n",
       " 'below_scroll': 88,\n",
       " 'above_mentioned': 89,\n",
       " 'following': 90,\n",
       " 'undermentioned': 91,\n",
       " 'above_salt': 92,\n",
       " 'below_salt': 93,\n",
       " 'above_water': 94,\n",
       " 'under_water': 95,\n",
       " 'aboveground': 96,\n",
       " 'belowground': 97,\n",
       " 'underground': 98,\n",
       " 'aboveness': 99,\n",
       " 'belowness': 100,\n",
       " 'abridgable': 101,\n",
       " 'unabridgable': 102,\n",
       " 'abrogate': 103,\n",
       " 'fix': 104,\n",
       " 'promulgate': 105,\n",
       " 'abruptly_pinnate': 106,\n",
       " 'imparipinnate': 107,\n",
       " 'odd_pinnate': 108,\n",
       " 'absence': 109,\n",
       " 'existence': 110,\n",
       " 'presence': 111,\n",
       " 'absence_makes_heart_grow_fonder': 112,\n",
       " 'long_absent_soon_forgotten': 113,\n",
       " 'absent': 114,\n",
       " 'present': 115,\n",
       " 'absolute': 116,\n",
       " 'conditional': 117,\n",
       " 'relative': 118,\n",
       " 'absolute_majority': 119,\n",
       " 'plurality': 120,\n",
       " 'relative_majority': 121,\n",
       " 'absolute_music': 122,\n",
       " 'program_music': 123,\n",
       " 'absoluteness': 124,\n",
       " 'conditionality': 125,\n",
       " 'limitedness': 126,\n",
       " 'relativity': 127,\n",
       " 'absolutism': 128,\n",
       " 'relativism': 129,\n",
       " 'absolutist': 130,\n",
       " 'relativist': 131,\n",
       " 'absolvitor': 132,\n",
       " 'condemnator': 133,\n",
       " 'absonant': 134,\n",
       " 'consonant': 135,\n",
       " 'absorb': 136,\n",
       " 'emit': 137,\n",
       " 'abstract': 138,\n",
       " 'applied': 139,\n",
       " 'concrete': 140,\n",
       " 'abstract_class': 141,\n",
       " 'concrete_class': 142,\n",
       " 'abstract_interface': 143,\n",
       " 'concrete_interface': 144,\n",
       " 'abstract_method': 145,\n",
       " 'concrete_method': 146,\n",
       " 'abstract_noun': 147,\n",
       " 'concrete_noun': 148,\n",
       " 'abstract_number': 149,\n",
       " 'concrete_number': 150,\n",
       " 'abstract_verb': 151,\n",
       " 'concrete_verb': 152,\n",
       " 'definite_verb': 153,\n",
       " 'determinate_verb': 154,\n",
       " 'abstraction': 155,\n",
       " 'concretization': 156,\n",
       " 'specialization': 157,\n",
       " 'abstractness': 158,\n",
       " 'concreteness': 159,\n",
       " 'abundance': 160,\n",
       " 'few': 161,\n",
       " 'abundant': 162,\n",
       " 'rare': 163,\n",
       " 'scarce': 164,\n",
       " 'ac': 165,\n",
       " 'ad': 166,\n",
       " 'dc': 167,\n",
       " 'academically': 168,\n",
       " 'non_academically': 169,\n",
       " 'acapnia': 170,\n",
       " 'hypercapnia': 171,\n",
       " 'accelerate': 172,\n",
       " 'decelerate': 173,\n",
       " 'retard': 174,\n",
       " 'acceleration': 175,\n",
       " 'deceleration': 176,\n",
       " 'accept': 177,\n",
       " 'decline': 178,\n",
       " 'deny': 179,\n",
       " 'refuse': 180,\n",
       " 'reject': 181,\n",
       " 'acceptability': 182,\n",
       " 'inacceptability': 183,\n",
       " 'unacceptability': 184,\n",
       " 'acceptable': 185,\n",
       " 'inacceptable': 186,\n",
       " 'unacceptable': 187,\n",
       " 'accessible': 188,\n",
       " 'inaccessible': 189,\n",
       " 'accession': 190,\n",
       " 'deaccession': 191,\n",
       " 'accessor': 192,\n",
       " 'mutator': 193,\n",
       " 'accident': 194,\n",
       " 'on_purpose': 195,\n",
       " 'planned': 196,\n",
       " 'purpose': 197,\n",
       " 'accidentally': 198,\n",
       " 'intentionally': 199,\n",
       " 'acclivity': 200,\n",
       " 'declivity': 201,\n",
       " 'acclivous': 202,\n",
       " 'declivous': 203,\n",
       " 'accommodate': 204,\n",
       " 'discommodate': 205,\n",
       " 'accountable': 206,\n",
       " 'unaccountable': 207,\n",
       " 'accountably': 208,\n",
       " 'irresponsibly': 209,\n",
       " 'unaccountably': 210,\n",
       " 'accretion': 211,\n",
       " 'attrition': 212,\n",
       " 'decay': 213,\n",
       " 'erosion': 214,\n",
       " 'accrue': 215,\n",
       " 'amortize': 216,\n",
       " 'accumulation': 217,\n",
       " 'decumulation': 218,\n",
       " 'accumulation_point': 219,\n",
       " 'isolated_point': 220,\n",
       " 'accuracy': 221,\n",
       " 'inaccuracy': 222,\n",
       " 'accurate': 223,\n",
       " 'inaccurate': 224,\n",
       " 'accurateness': 225,\n",
       " 'inaccurateness': 226,\n",
       " 'accusatorial': 227,\n",
       " 'inquisitorial': 228,\n",
       " 'acerebral': 229,\n",
       " 'cerebral': 230,\n",
       " 'achieved_status': 231,\n",
       " 'ascribed_status': 232,\n",
       " 'achiral': 233,\n",
       " 'chiral': 234,\n",
       " 'acholia': 235,\n",
       " 'cholaemia': 236,\n",
       " 'acid': 237,\n",
       " 'alkaline': 238,\n",
       " 'base': 239,\n",
       " 'alkali': 240,\n",
       " 'acidic': 241,\n",
       " 'basic': 242,\n",
       " 'acidification': 243,\n",
       " 'basification': 244,\n",
       " 'acidify': 245,\n",
       " 'alkalify': 246,\n",
       " 'basify': 247,\n",
       " 'acidity': 248,\n",
       " 'alkalinity': 249,\n",
       " 'ack': 250,\n",
       " 'nak': 251,\n",
       " 'nack': 252,\n",
       " 'acme': 253,\n",
       " 'nadir': 254,\n",
       " 'acoloutha': 255,\n",
       " 'anacoloutha': 256,\n",
       " 'acquit': 257,\n",
       " 'condemn': 258,\n",
       " 'acquittal': 259,\n",
       " 'condemnation': 260,\n",
       " 'conviction': 261,\n",
       " 'acrimony': 262,\n",
       " 'friendship': 263,\n",
       " 'peace': 264,\n",
       " 'acrogynous': 265,\n",
       " 'anacrogynous': 266,\n",
       " 'acronycal': 267,\n",
       " 'cosmical': 268,\n",
       " 'acropetal': 269,\n",
       " 'basipetal': 270,\n",
       " 'acrophase': 271,\n",
       " 'bathyphase': 272,\n",
       " 'trough': 273,\n",
       " 'acrophobia': 274,\n",
       " 'bathophobia': 275,\n",
       " 'acrophyll': 276,\n",
       " 'bathyphyll': 277,\n",
       " 'acroscopic': 278,\n",
       " 'basiscopic': 279,\n",
       " 'across': 280,\n",
       " 'crossword': 281,\n",
       " 'crossword_down': 282,\n",
       " 'down': 283,\n",
       " 'parallel': 284,\n",
       " 'across_variable': 285,\n",
       " 'through_variable': 286,\n",
       " 'act': 287,\n",
       " 'be_real': 288,\n",
       " 'do': 289,\n",
       " 'do_nothing': 290,\n",
       " 'nothing': 291,\n",
       " 'real': 292,\n",
       " 'actifan': 293,\n",
       " 'passifan': 294,\n",
       " 'action': 295,\n",
       " 'inaction': 296,\n",
       " 'actions_speak_louder_than_words': 297,\n",
       " 'pen_is_mightier_than_sword': 298,\n",
       " 'activate': 299,\n",
       " 'deactivate': 300,\n",
       " 'disactivate': 301,\n",
       " 'active': 302,\n",
       " 'inactive': 303,\n",
       " 'active_duty': 304,\n",
       " 'reserve': 305,\n",
       " 'activity': 306,\n",
       " 'inactivity': 307,\n",
       " 'passivity': 308,\n",
       " 'rest': 309,\n",
       " 'actual': 310,\n",
       " 'fake': 311,\n",
       " 'fake_simulated': 312,\n",
       " 'pretend': 313,\n",
       " 'simulated': 314,\n",
       " 'smaller': 315,\n",
       " 'future': 316,\n",
       " 'potential': 317,\n",
       " 'actualization': 318,\n",
       " 'deactualization': 319,\n",
       " 'acute_toxicity': 320,\n",
       " 'chronic_toxicity': 321,\n",
       " 'acyanophilous': 322,\n",
       " 'cyanophilous': 323,\n",
       " 'acyclic': 324,\n",
       " 'cyclic': 325,\n",
       " 'bc': 326,\n",
       " 'ad_hominem': 327,\n",
       " 'ad_verecundiam': 328,\n",
       " 'appeal_to_authority': 329,\n",
       " 'ipse_dixit': 330,\n",
       " 'adam_teasing': 331,\n",
       " 'eve_teasing': 332,\n",
       " 'adapical': 333,\n",
       " 'adbasal': 334,\n",
       " 'add': 335,\n",
       " 'subtract': 336,\n",
       " 'subtraction': 337,\n",
       " 'take': 338,\n",
       " 'take_away': 339,\n",
       " 'remove': 340,\n",
       " 'adder': 341,\n",
       " 'addicting': 342,\n",
       " 'nonaddictive': 343,\n",
       " 'addictive': 344,\n",
       " 'addition': 345,\n",
       " 'reduction': 346,\n",
       " 'additive': 347,\n",
       " 'subtractive': 348,\n",
       " 'addressable': 349,\n",
       " 'unaddressable': 350,\n",
       " 'addressee': 351,\n",
       " 'sender': 352,\n",
       " 'speaker': 353,\n",
       " 'adept': 354,\n",
       " 'inept': 355,\n",
       " 'adequate': 356,\n",
       " 'inadequate': 357,\n",
       " 'adfix': 358,\n",
       " 'infix': 359,\n",
       " 'adhesion': 360,\n",
       " 'cohesion': 361,\n",
       " 'adiabatic': 362,\n",
       " 'diabatic': 363,\n",
       " 'nonadiabatic': 364,\n",
       " 'adjacent': 365,\n",
       " 'apart': 366,\n",
       " 'adjectival_pronoun': 367,\n",
       " 'substantival_pronoun': 368,\n",
       " 'adjoining': 369,\n",
       " 'separated': 370,\n",
       " 'administrative': 371,\n",
       " 'non_administrative': 372,\n",
       " 'admire': 373,\n",
       " 'despise': 374,\n",
       " 'admissibility': 375,\n",
       " 'inadmissibility': 376,\n",
       " 'admissible': 377,\n",
       " 'inadmissible': 378,\n",
       " 'admit': 379,\n",
       " 'admittable': 380,\n",
       " 'unadmittable': 381,\n",
       " 'adnate': 382,\n",
       " 'connate': 383,\n",
       " 'adonist': 384,\n",
       " 'jehovist': 385,\n",
       " 'adopt': 386,\n",
       " 'biological': 387,\n",
       " 'biological_child': 388,\n",
       " 'birth': 389,\n",
       " 'child': 390,\n",
       " 'children': 391,\n",
       " 'give': 392,\n",
       " 'give_away': 393,\n",
       " 'orphan': 394,\n",
       " 'own': 395,\n",
       " 'own_children': 396,\n",
       " 'adoration': 397,\n",
       " 'disdain': 398,\n",
       " 'adore': 399,\n",
       " 'adret': 400,\n",
       " 'ubac': 401,\n",
       " 'adroit': 402,\n",
       " 'clumsy': 403,\n",
       " 'maladroit': 404,\n",
       " 'adsorbent': 405,\n",
       " 'nonadsorbent': 406,\n",
       " 'adsorption': 407,\n",
       " 'desorption': 408,\n",
       " 'adsorptive': 409,\n",
       " 'nonadsorptive': 410,\n",
       " 'adult': 411,\n",
       " 'adulteration': 412,\n",
       " 'purification': 413,\n",
       " 'adulthood': 414,\n",
       " 'childhood': 415,\n",
       " 'adultish': 416,\n",
       " 'childish': 417,\n",
       " 'advance': 418,\n",
       " 'backward': 419,\n",
       " 'going': 420,\n",
       " 'going_backward': 421,\n",
       " 'late': 422,\n",
       " 'late_payment': 423,\n",
       " 'payment': 424,\n",
       " 'retreat': 425,\n",
       " 'advantage': 426,\n",
       " 'con': 427,\n",
       " 'handicap': 428,\n",
       " 'disadvantage': 429,\n",
       " 'advantageously': 430,\n",
       " 'disadvantageously': 431,\n",
       " 'advehent': 432,\n",
       " 'revehent': 433,\n",
       " 'adventure': 434,\n",
       " 'boring': 435,\n",
       " 'lazy': 436,\n",
       " 'abstention': 437,\n",
       " 'adventurous': 438,\n",
       " 'nervous': 439,\n",
       " 'safe': 440,\n",
       " 'adverb': 441,\n",
       " 'adjective': 442,\n",
       " 'pronoun': 443,\n",
       " 'adversarial': 444,\n",
       " 'cooperative': 445,\n",
       " 'adverse_effect': 446,\n",
       " 'desired_effect': 447,\n",
       " 'advertent': 448,\n",
       " 'inadvertent': 449,\n",
       " 'advisability': 450,\n",
       " 'inadvisability': 451,\n",
       " 'advisory': 452,\n",
       " 'mandatory': 453,\n",
       " 'aequihymeniiferous': 454,\n",
       " 'inaequihymeniiferous': 455,\n",
       " 'aerobic': 456,\n",
       " 'anaerobic': 457,\n",
       " 'aerobiosis': 458,\n",
       " 'anaerobiosis': 459,\n",
       " 'aerobiotic': 460,\n",
       " 'nonaerobiotic': 461,\n",
       " 'aerodyne': 462,\n",
       " 'aerostat': 463,\n",
       " 'aerophyte': 464,\n",
       " 'anaerophyte': 465,\n",
       " 'aesthetic': 466,\n",
       " 'inaesthetic': 467,\n",
       " 'unaesthetic': 468,\n",
       " 'aesthetical': 469,\n",
       " 'aestival': 470,\n",
       " 'brumal': 471,\n",
       " 'hibernal': 472,\n",
       " 'aff': 473,\n",
       " 'neg': 474,\n",
       " 'affair': 475,\n",
       " 'faithful': 476,\n",
       " 'faithful_activity': 477,\n",
       " 'fidelity': 478,\n",
       " 'loyal': 479,\n",
       " 'marriage': 480,\n",
       " 'relationship': 481,\n",
       " 'afferent': 482,\n",
       " 'efferent': 483,\n",
       " 'afferently': 484,\n",
       " 'efferently': 485,\n",
       " 'affinal': 486,\n",
       " 'consanguine': 487,\n",
       " 'affirm': 488,\n",
       " 'affirmative': 489,\n",
       " 'negative': 490,\n",
       " 'affix': 491,\n",
       " 'nonaffix': 492,\n",
       " 'affluence': 493,\n",
       " 'indigence': 494,\n",
       " 'affluent': 495,\n",
       " 'indigent': 496,\n",
       " 'afford': 497,\n",
       " 'expensive': 498,\n",
       " 'too': 499,\n",
       " 'too_expensive': 500,\n",
       " 'affordable': 501,\n",
       " 'afforest': 502,\n",
       " 'deforest': 503,\n",
       " 'afforestation': 504,\n",
       " 'deforestation': 505,\n",
       " 'aforementioned': 506,\n",
       " 'aforesaid': 507,\n",
       " 'aft': 508,\n",
       " 'fore': 509,\n",
       " 'after': 510,\n",
       " 'before': 511,\n",
       " 'afterbear': 512,\n",
       " 'forebear': 513,\n",
       " 'afterbeat': 514,\n",
       " 'forebeat': 515,\n",
       " 'afterbrain': 516,\n",
       " 'forebrain': 517,\n",
       " 'afterdeal': 518,\n",
       " 'foredeal': 519,\n",
       " 'aftergame': 520,\n",
       " 'foregame': 521,\n",
       " 'afterglow': 522,\n",
       " 'foreglow': 523,\n",
       " 'hangover': 524,\n",
       " 'post_coital_tristesse': 525,\n",
       " 'afterhand': 526,\n",
       " 'beforehand': 527,\n",
       " 'forehand': 528,\n",
       " 'afterlife': 529,\n",
       " 'forelife': 530,\n",
       " 'aftermarket': 531,\n",
       " 'oem': 532,\n",
       " 'aftername': 533,\n",
       " 'forename': 534,\n",
       " 'afternoon': 535,\n",
       " 'before_lunch': 536,\n",
       " 'before_noon': 537,\n",
       " 'evening': 538,\n",
       " 'lunch': 539,\n",
       " 'morning': 540,\n",
       " 'noon': 541,\n",
       " 'aftersee': 542,\n",
       " 'foresee': 543,\n",
       " 'afterset': 544,\n",
       " 'foreset': 545,\n",
       " 'aftershock': 546,\n",
       " 'foreshock': 547,\n",
       " 'aftersound': 548,\n",
       " 'foresound': 549,\n",
       " 'afterstroke': 550,\n",
       " 'appoggiatura': 551,\n",
       " 'aftertest': 552,\n",
       " 'foretest': 553,\n",
       " 'afterthinker': 554,\n",
       " 'forethinker': 555,\n",
       " 'afterward': 556,\n",
       " 'afterwards': 557,\n",
       " 'again': 558,\n",
       " 'never': 559,\n",
       " 'once': 560,\n",
       " 'stop': 561,\n",
       " 'stop_trying': 562,\n",
       " 'trying': 563,\n",
       " 'against': 564,\n",
       " 'away': 565,\n",
       " 'away_from': 566,\n",
       " 'being': 567,\n",
       " 'being_for': 568,\n",
       " 'for': 569,\n",
       " 'for_or': 570,\n",
       " 'for_someone': 571,\n",
       " 'someone': 572,\n",
       " 'with': 573,\n",
       " 'age': 574,\n",
       " 'getting': 575,\n",
       " 'getting_younger': 576,\n",
       " 'grow': 577,\n",
       " 'grow_young': 578,\n",
       " 'human': 579,\n",
       " 'human_years': 580,\n",
       " 'number': 581,\n",
       " 'number_years': 582,\n",
       " 'old': 583,\n",
       " 'years': 584,\n",
       " 'young': 585,\n",
       " 'younger': 586,\n",
       " 'youth': 587,\n",
       " 'agent': 588,\n",
       " 'patient': 589,\n",
       " 'aggravate': 590,\n",
       " 'mitigate': 591,\n",
       " 'aggregant': 592,\n",
       " 'antiaggregant': 593,\n",
       " 'aggregatable': 594,\n",
       " 'unaggregatable': 595,\n",
       " 'aggregate': 596,\n",
       " 'segregate': 597,\n",
       " 'aggregation': 598,\n",
       " 'disgregation': 599,\n",
       " 'aggression': 600,\n",
       " 'nonaggression': 601,\n",
       " 'aggressive': 602,\n",
       " 'passive': 603,\n",
       " 'agile': 604,\n",
       " 'unagile': 605,\n",
       " 'agitator': 606,\n",
       " 'agitatee': 607,\n",
       " 'agnate': 608,\n",
       " 'enate': 609,\n",
       " 'agnosis': 610,\n",
       " 'gnosis': 611,\n",
       " 'ago': 612,\n",
       " 'agony': 613,\n",
       " 'bliss': 614,\n",
       " 'defeat': 615,\n",
       " 'ecstasy': 616,\n",
       " 'agrammatical': 617,\n",
       " 'grammatical': 618,\n",
       " 'agree': 619,\n",
       " 'argue': 620,\n",
       " 'disagreement': 621,\n",
       " 'disagree': 622,\n",
       " 'agree_with': 623,\n",
       " 'disagree_with': 624,\n",
       " 'agreement': 625,\n",
       " 'dispute': 626,\n",
       " 'agromania': 627,\n",
       " 'agrophobia': 628,\n",
       " 'ahead': 629,\n",
       " 'behind': 630,\n",
       " 'ahermatypic': 631,\n",
       " 'hermatypic': 632,\n",
       " 'ahle_hadith': 633,\n",
       " 'ahle_quran': 634,\n",
       " 'aibohphobia': 635,\n",
       " 'ailihphilia': 636,\n",
       " 'ailurophile': 637,\n",
       " 'ailurophobe': 638,\n",
       " 'ailurophilia': 639,\n",
       " 'ailurophobia': 640,\n",
       " 'galeophobia': 641,\n",
       " 'ailurophilic': 642,\n",
       " 'ailurophobic': 643,\n",
       " 'aimful': 644,\n",
       " 'aimless': 645,\n",
       " 'aimfully': 646,\n",
       " 'aimlessly': 647,\n",
       " 'air': 648,\n",
       " 'earth': 649,\n",
       " 'fire': 650,\n",
       " 'ground': 651,\n",
       " 'land': 652,\n",
       " 'vacuum': 653,\n",
       " 'water': 654,\n",
       " 'water_fire': 655,\n",
       " 'airable': 656,\n",
       " 'unairable': 657,\n",
       " 'airside': 658,\n",
       " 'landside': 659,\n",
       " 'airworthiness': 660,\n",
       " 'unairworthiness': 661,\n",
       " 'airworthy': 662,\n",
       " 'unflyable': 663,\n",
       " 'alacrity': 664,\n",
       " 'apathy': 665,\n",
       " 'disinclination': 666,\n",
       " 'hesitance': 667,\n",
       " 'indifference': 668,\n",
       " 'reluctance': 669,\n",
       " 'albino': 670,\n",
       " 'hypermelanistic': 671,\n",
       " 'hypermelanoid': 672,\n",
       " 'alcoholic': 673,\n",
       " 'nonalcoholic': 674,\n",
       " 'teetotaler': 675,\n",
       " 'algebraic': 676,\n",
       " 'transcendental': 677,\n",
       " 'algebraic_number': 678,\n",
       " 'transcendental_number': 679,\n",
       " 'alien': 680,\n",
       " 'alienable': 681,\n",
       " 'inalienable': 682,\n",
       " 'alikeness': 683,\n",
       " 'unalikeness': 684,\n",
       " 'aliovalent': 685,\n",
       " 'isovalent': 686,\n",
       " 'aliphatic': 687,\n",
       " 'aromatic': 688,\n",
       " 'aliquot': 689,\n",
       " 'aliquant': 690,\n",
       " 'alive': 691,\n",
       " 'dead': 692,\n",
       " 'aliyah': 693,\n",
       " 'yerida': 694,\n",
       " 'all': 695,\n",
       " 'none': 696,\n",
       " 'alleviable': 697,\n",
       " 'unalleviable': 698,\n",
       " 'alligator': 699,\n",
       " 'crocodile': 700,\n",
       " 'allo': 701,\n",
       " 'auto': 702,\n",
       " 'allocate': 703,\n",
       " 'free': 704,\n",
       " 'allocentric': 705,\n",
       " 'autocentric': 706,\n",
       " 'egocentric': 707,\n",
       " 'idiocentric': 708,\n",
       " 'self_absorbed': 709,\n",
       " 'self_centered': 710,\n",
       " 'selfish': 711,\n",
       " 'allocentrism': 712,\n",
       " 'autocentrism': 713,\n",
       " 'allochthonous': 714,\n",
       " 'autochthonous': 715,\n",
       " 'alloerotic': 716,\n",
       " 'analloerotic': 717,\n",
       " 'alloeroticism': 718,\n",
       " 'autoeroticism': 719,\n",
       " 'allopoiesis': 720,\n",
       " 'autopoiesis': 721,\n",
       " 'allopolyploidy': 722,\n",
       " 'autopolyploidy': 723,\n",
       " 'allosexual': 724,\n",
       " 'asexual': 725,\n",
       " 'autosexual': 726,\n",
       " 'heterosexual': 727,\n",
       " 'isosexual': 728,\n",
       " 'allospecific': 729,\n",
       " 'conspecific': 730,\n",
       " 'allow': 731,\n",
       " 'forbid': 732,\n",
       " 'permitted': 733,\n",
       " 'prohibit': 734,\n",
       " 'restrict': 735,\n",
       " 'allowed': 736,\n",
       " 'forbidden': 737,\n",
       " 'prohibited': 738,\n",
       " 'ally': 739,\n",
       " 'enemy': 740,\n",
       " 'almost': 741,\n",
       " 'exact': 742,\n",
       " 'alogical': 743,\n",
       " 'logical': 744,\n",
       " 'alone': 745,\n",
       " 'crowd': 746,\n",
       " 'crowded': 747,\n",
       " 'in_crowd': 748,\n",
       " 'many_people': 749,\n",
       " 'others': 750,\n",
       " 'people': 751,\n",
       " 'together': 752,\n",
       " 'with_others': 753,\n",
       " 'with_people': 754,\n",
       " 'with_someone': 755,\n",
       " 'along': 756,\n",
       " 'short': 757,\n",
       " 'aloud': 758,\n",
       " 'in_whisper': 759,\n",
       " 'alphabet': 760,\n",
       " 'already': 761,\n",
       " 'yet': 762,\n",
       " 'alt_left': 763,\n",
       " 'alt_right': 764,\n",
       " 'alterable': 765,\n",
       " 'inalterable': 766,\n",
       " 'unalterable': 767,\n",
       " 'alternating_current': 768,\n",
       " 'direct_current': 769,\n",
       " 'although': 770,\n",
       " 'because': 771,\n",
       " 'altophobia': 772,\n",
       " 'altrices': 773,\n",
       " 'praecoces': 774,\n",
       " 'altruism': 775,\n",
       " 'egoism': 776,\n",
       " 'altruist': 777,\n",
       " 'egoist': 778,\n",
       " 'altruistic': 779,\n",
       " 'egoistic': 780,\n",
       " 'misanthropic': 781,\n",
       " 'altruistically': 782,\n",
       " 'egoistically': 783,\n",
       " 'misanthropically': 784,\n",
       " 'selfishly': 785,\n",
       " 'always': 786,\n",
       " 'seldom': 787,\n",
       " 'sometimes': 788,\n",
       " 'sometimes_never': 789,\n",
       " 'am': 790,\n",
       " 'pm': 791,\n",
       " 'amalgamate': 792,\n",
       " 'separate': 793,\n",
       " 'amateur': 794,\n",
       " 'professional': 795,\n",
       " 'amber': 796,\n",
       " 'red': 797,\n",
       " 'ambidextrous': 798,\n",
       " 'ambilevous': 799,\n",
       " 'ambisinistrous': 800,\n",
       " 'ambiguate': 801,\n",
       " 'disambiguate': 802,\n",
       " 'ambiguation': 803,\n",
       " 'disambiguation': 804,\n",
       " 'ambiguity': 805,\n",
       " 'unambiguity': 806,\n",
       " 'ambiguous': 807,\n",
       " 'precise': 808,\n",
       " 'unambiguous': 809,\n",
       " 'ameliorate': 810,\n",
       " 'deteriorate': 811,\n",
       " 'worsen': 812,\n",
       " 'amelioratingly': 813,\n",
       " 'deterioratingly': 814,\n",
       " 'amelioration': 815,\n",
       " 'deterioration': 816,\n",
       " 'amenable': 817,\n",
       " 'unamenable': 818,\n",
       " 'american_quotation': 819,\n",
       " 'british_quotation': 820,\n",
       " 'logical_quotation': 821,\n",
       " 'oxford_quotation': 822,\n",
       " 'americanism': 823,\n",
       " 'anti_americanism': 824,\n",
       " 'briticism': 825,\n",
       " 'amity': 826,\n",
       " 'enemyship': 827,\n",
       " 'enmity': 828,\n",
       " 'hostility': 829,\n",
       " 'ammiyya': 830,\n",
       " 'fus_ha': 831,\n",
       " 'among': 832,\n",
       " 'between': 833,\n",
       " 'amphichiral': 834,\n",
       " 'amusable': 835,\n",
       " 'unamusable': 836,\n",
       " 'amusing': 837,\n",
       " 'unamusing': 838,\n",
       " 'an': 839,\n",
       " 'the': 840,\n",
       " 'ana': 841,\n",
       " 'kata': 842,\n",
       " 'anabasis': 843,\n",
       " 'catabasis': 844,\n",
       " 'katabasis': 845,\n",
       " 'anabatic': 846,\n",
       " 'katabatic': 847,\n",
       " 'anabolic': 848,\n",
       " 'catabolic': 849,\n",
       " 'anadromous': 850,\n",
       " 'catadromous': 851,\n",
       " 'analog': 852,\n",
       " 'digital': 853,\n",
       " 'discrete': 854,\n",
       " 'analog_to_digital_converter': 855,\n",
       " 'digital_to_analog_converter': 856,\n",
       " 'analogue': 857,\n",
       " 'analysis': 858,\n",
       " 'synthesis': 859,\n",
       " 'analytic': 860,\n",
       " 'contingent': 861,\n",
       " 'analytic_philosophy': 862,\n",
       " 'continental_philosophy': 863,\n",
       " 'anaphor': 864,\n",
       " 'logophor': 865,\n",
       " 'anapodeictic': 866,\n",
       " 'apodeictic': 867,\n",
       " 'anaptyxis': 868,\n",
       " 'excrescence': 869,\n",
       " 'anarchist': 870,\n",
       " 'archist': 871,\n",
       " 'anarchy': 872,\n",
       " 'nonanarchy': 873,\n",
       " 'order': 874,\n",
       " 'anasteemaphilia': 875,\n",
       " 'anasteemaphobia': 876,\n",
       " 'anatropous': 877,\n",
       " 'orthotropous': 878,\n",
       " 'anauxotelic': 879,\n",
       " 'auxotelic': 880,\n",
       " 'ancestor': 881,\n",
       " 'descendant': 882,\n",
       " 'ancient': 883,\n",
       " 'new': 884,\n",
       " 'modern': 885,\n",
       " 'and': 886,\n",
       " 'but': 887,\n",
       " 'er': 888,\n",
       " 'nand': 889,\n",
       " 'andro': 890,\n",
       " 'gyno': 891,\n",
       " 'androcentrism': 892,\n",
       " 'gynocentrism': 893,\n",
       " 'androphobe': 894,\n",
       " 'androphile': 895,\n",
       " 'gynophobe': 896,\n",
       " 'androphobia': 897,\n",
       " 'androphilia': 898,\n",
       " 'gynophobia': 899,\n",
       " 'anelectric': 900,\n",
       " 'idioelectric': 901,\n",
       " 'anergy': 902,\n",
       " 'exergy': 903,\n",
       " 'free_energy': 904,\n",
       " 'synergy': 905,\n",
       " 'anger': 906,\n",
       " 'calm': 907,\n",
       " 'happiness': 908,\n",
       " 'sweetness': 909,\n",
       " 'angerless': 910,\n",
       " 'angerful': 911,\n",
       " 'angry': 912,\n",
       " 'anglophile': 913,\n",
       " 'anglophobe': 914,\n",
       " 'anglophilia': 915,\n",
       " 'anglophobia': 916,\n",
       " 'anglophilic': 917,\n",
       " 'anglophobic': 918,\n",
       " 'angstful': 919,\n",
       " 'angstless': 920,\n",
       " 'angustimurate': 921,\n",
       " 'latimurate': 922,\n",
       " 'anhedral': 923,\n",
       " 'euhedral': 924,\n",
       " 'dihedral': 925,\n",
       " 'anhysteretic': 926,\n",
       " 'hysteretic': 927,\n",
       " 'animal': 928,\n",
       " 'bird': 929,\n",
       " 'human_plants': 930,\n",
       " 'man': 931,\n",
       " 'mineral': 932,\n",
       " 'mineral_vegetable': 933,\n",
       " 'person': 934,\n",
       " 'plant': 935,\n",
       " 'plants': 936,\n",
       " 'vegetable': 937,\n",
       " 'vegetable_mineral': 938,\n",
       " 'animalculism': 939,\n",
       " 'ovism': 940,\n",
       " 'animate': 941,\n",
       " 'fixed': 942,\n",
       " 'inanimate': 943,\n",
       " 'static': 944,\n",
       " 'animosity': 945,\n",
       " 'anisodiametric': 946,\n",
       " 'isodiametric': 947,\n",
       " 'anisospore': 948,\n",
       " 'isospore': 949,\n",
       " 'anisosyllabic': 950,\n",
       " 'isosyllabic': 951,\n",
       " 'anisosyllabism': 952,\n",
       " 'isosyllabism': 953,\n",
       " 'anisotropic': 954,\n",
       " 'isotropic': 955,\n",
       " 'anisotropy': 956,\n",
       " 'isotropy': 957,\n",
       " 'aniṭ': 958,\n",
       " 'seṭ': 959,\n",
       " 'ankle': 960,\n",
       " 'wrist': 961,\n",
       " 'annex': 962,\n",
       " 'annexable': 963,\n",
       " 'separable': 964,\n",
       " 'unannexable': 965,\n",
       " 'annexation': 966,\n",
       " 'separation': 967,\n",
       " 'annihilate': 968,\n",
       " 'create': 969,\n",
       " 'annihilation': 970,\n",
       " 'creation': 971,\n",
       " 'generation': 972,\n",
       " 'annihilative': 973,\n",
       " 'creative': 974,\n",
       " 'generative': 975,\n",
       " 'anno_domini': 976,\n",
       " 'before_christ': 977,\n",
       " 'before_common_era': 978,\n",
       " 'announcement': 979,\n",
       " 'denounce': 980,\n",
       " 'annoy': 981,\n",
       " 'please': 982,\n",
       " 'anode': 983,\n",
       " 'cathode': 984,\n",
       " 'anoikism': 985,\n",
       " 'synoikism': 986,\n",
       " 'anomotreme': 987,\n",
       " 'nomotreme': 988,\n",
       " 'anonymous': 989,\n",
       " 'onymous': 990,\n",
       " 'anopia': 991,\n",
       " 'observance': 992,\n",
       " 'sight': 993,\n",
       " 'anosmic': 994,\n",
       " 'hyperosmic': 995,\n",
       " 'osmatic': 996,\n",
       " 'another': 997,\n",
       " 'one': 998,\n",
       " 'anothermal': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict of conceptnet token\n",
    "# key = token name, value = id\n",
    "concept2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept2id['ab_extra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab_extra'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2concept[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看 relation2id 內的東西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antonym': 0,\n",
       " 'atlocation': 1,\n",
       " 'capableof': 2,\n",
       " 'causes': 3,\n",
       " 'createdby': 4,\n",
       " 'isa': 5,\n",
       " 'desires': 6,\n",
       " 'hassubevent': 7,\n",
       " 'partof': 8,\n",
       " 'hascontext': 9,\n",
       " 'hasproperty': 10,\n",
       " 'madeof': 11,\n",
       " 'notcapableof': 12,\n",
       " 'notdesires': 13,\n",
       " 'receivesaction': 14,\n",
       " 'relatedto': 15,\n",
       " 'usedfor': 16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict of relation\n",
    "# key = token name, value = id\n",
    "relation2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antonym',\n",
       " 'atlocation',\n",
       " 'capableof',\n",
       " 'causes',\n",
       " 'createdby',\n",
       " 'isa',\n",
       " 'desires',\n",
       " 'hassubevent',\n",
       " 'partof',\n",
       " 'hascontext',\n",
       " 'hasproperty',\n",
       " 'madeof',\n",
       " 'notcapableof',\n",
       " 'notdesires',\n",
       " 'receivesaction',\n",
       " 'relatedto',\n",
       " 'usedfor']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2relation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將預處理的資料 整理成 QA Data Format\n",
    "## Data format 資料格式\n",
    "qa_data 格式 \n",
    "- data : <tuple>\n",
    "    - q_ids : <set> : q_ids 所有在 question 句子中的 phase verb noun 的 id\n",
    "    - a_ids : <set> : a_ids 所有在 answer 句子中的 phase verb noun 的 id\n",
    "    - QAcontext : <str> : 綜合 Question 以及 Answer 的文字，用空白互相格開"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/user_data/dggnn/data/MCQ/statement/test.statement.jsonl'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data = []\n",
    "statement_path = grounded_path.replace('grounded', 'statement')\n",
    "statement_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = []\n",
    "with open(grounded_path, 'r', encoding='utf-8') as fin_ground:\n",
    "    lines_ground = fin_ground.readlines()\n",
    "    for j, line in enumerate(lines_ground):\n",
    "        dic = json.loads(line)\n",
    "        q_ids = set(concept2id[c] for c in dic['qc'])\n",
    "        a_ids = set(concept2id[c] for c in dic['ac'])\n",
    "        q_ids = q_ids - a_ids\n",
    "        sentence = dic['sent'].replace(dic['ans'],'[MASK]')\n",
    "        QAcontext = \"{}.[SEP] {}.\".format(sentence, dic['ans'])\n",
    "        qa_data.append((q_ids, a_ids, QAcontext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共有 259 筆\n"
     ]
    }
   ],
   "source": [
    "print('總共有',len(qa_data),'筆')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({928,\n",
       "  3996,\n",
       "  4958,\n",
       "  10627,\n",
       "  10998,\n",
       "  12541,\n",
       "  15816,\n",
       "  41365,\n",
       "  74204,\n",
       "  79152,\n",
       "  80083,\n",
       "  195118,\n",
       "  380952,\n",
       "  387476},\n",
       " {172893},\n",
       " '[MASK] is used to describe a chemical released by an animal that affects the behavior or physiology of animals of the same species.[SEP] pheromone.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': 'In sexual reproduction , sperm is the name of the gamete cell the male must contribute ',\n",
       " 'ans': 'sperm',\n",
       " 'qc': ['cell',\n",
       "  'contribute',\n",
       "  'gamete',\n",
       "  'male',\n",
       "  'must',\n",
       "  'name',\n",
       "  'reproduction',\n",
       "  'sexual',\n",
       "  'sexual_reproduction'],\n",
       " 'ac': ['sperm']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = json.loads(line)\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_ids  {3013, 5414, 11274, 129516, 11310, 363984, 1460, 1462, 12119}\n",
      "a_ids  {6010}\n"
     ]
    }
   ],
   "source": [
    "q_ids = set(concept2id[c] for c in dic['qc'])\n",
    "a_ids = set(concept2id[c] for c in dic['ac'])\n",
    "print('q_ids ',q_ids)\n",
    "print('a_ids ',a_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_ids =  {3013, 5414, 11274, 129516, 11310, 363984, 1460, 1462, 12119}\n",
      "a_ids =  {6010}\n",
      "QAcontext =  In sexual reproduction , [MASK] is the name of the gamete cell the male must contribute .[SEP] sperm.\n"
     ]
    }
   ],
   "source": [
    "last_data = qa_data[-1]\n",
    "print('q_ids = ',last_data[0])\n",
    "print('a_ids = ',last_data[1])\n",
    "print('QAcontext = ',last_data[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concepts_to_adj_matrices_2hop_all_pair__use_LM__Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1460, 1462, 3013, 5414, 6010, 11274, 11310, 12119, 129516, 363984}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_ids, ac_ids, question = qa_data[-1]\n",
    "# 合併 qc_ids 與 ac_ids\n",
    "qa_nodes = set(qc_ids) | set(ac_ids)\n",
    "qa_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In sexual reproduction , [MASK] is the name of the gamete cell the male must contribute .[SEP] sperm.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question.replace('vector','[MASK]',1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入 ChatGPT Candidate Set 並用來 retrieve 其他的 relevant node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chatgpt_data(item):\n",
    "    path = '../candidate_data/chatgpt_prompt1/chatgpt_{}_candidate(cleaned).json'.format(item)\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data = read_chatgpt_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT\n",
      "question in first data =  **blank** is used to describe a chemical released by an animal that affects the behavior or physiology of animals of the same species\n",
      "answer in first data =  pheromone\n",
      "distractors in first data =  ['enzyme', 'isolate', 'amino']\n",
      "candidate_set in first data =  ['Hormone', 'Enzyme', 'Antibody', 'Protease', 'Neurotransmitter', 'Toxin', 'Antioxidant', 'Catalyst', 'Carbohydrate', 'Lipid']\n"
     ]
    }
   ],
   "source": [
    "print('ChatGPT')\n",
    "print('question in first data = ',chat_data[0]['sentence'])\n",
    "print('answer in first data = ',chat_data[0]['answer'])\n",
    "print('distractors in first data = ',chat_data[0]['distractors'])\n",
    "print('candidate_set in first data = ',chat_data[0]['candidate_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(qa_data)):\n",
    "    print(i)\n",
    "    candidate = chat_data[i]['candidate_set']\n",
    "    pred = []\n",
    "    for x in candidate:\n",
    "        pred.append(x.lower())\n",
    "    \n",
    "    qa_data[i] = qa_data[i] + tuple(pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({928,\n",
       "  3996,\n",
       "  4958,\n",
       "  10627,\n",
       "  10998,\n",
       "  12541,\n",
       "  15816,\n",
       "  41365,\n",
       "  74204,\n",
       "  79152,\n",
       "  80083,\n",
       "  195118,\n",
       "  380952,\n",
       "  387476},\n",
       " {172893},\n",
       " '[MASK] is used to describe a chemical released by an animal that affects the behavior or physiology of animals of the same species.[SEP] pheromone.',\n",
       " 'hormone',\n",
       " 'enzyme',\n",
       " 'antibody',\n",
       " 'protease',\n",
       " 'neurotransmitter',\n",
       " 'toxin',\n",
       " 'antioxidant',\n",
       " 'catalyst',\n",
       " 'carbohydrate',\n",
       " 'lipid')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入 MLM Candidate Set 並用來 retrieve 其他的 relevant node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 08:10:35.415144: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-14 08:10:35.533283: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-14 08:10:35.929993: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-14 08:10:35.930150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-14 08:10:35.930158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"AndyChiang/cdgp-csg-scibert-dgen\")\n",
    "csg_model = BertForMaskedLM.from_pretrained(\"AndyChiang/cdgp-csg-scibert-dgen\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 10，找 10 個 prediction prob 最高的當 distractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasker = pipeline(\"fill-mask\", tokenizer=tokenizer, model=csg_model, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.3574290871620178, 'token': 15497, 'token_str': 'mars', 'sequence': 'the only known planet with large amounts of water is mars. earth'}\n"
     ]
    }
   ],
   "source": [
    "## example\n",
    "sent = \"The only known planet with large amounts of water is [MASK]. [SEP] earth\"\n",
    "cs = unmasker(sent)\n",
    "print(cs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(qa_data)):\n",
    "    sentence = chat_data[i]['sentence'].replace('**blank**','[MASK]')\n",
    "    pred = []\n",
    "    mlm_distractors_set = unmasker(sentence)\n",
    "    if len(mlm_distractors_set) < 5:\n",
    "        for each_distractor_set in mlm_distractors_set:\n",
    "            for distractor in each_distractor_set:\n",
    "                if distractor['token_str'] not in qa_data[i]:\n",
    "                    pred.append(distractor['token_str'].lower())\n",
    "    else:\n",
    "        for distractor in mlm_distractors_set:\n",
    "            if distractor['token_str'] not in qa_data[i]:\n",
    "                pred.append(distractor['token_str'].lower())\n",
    "    \n",
    "    qa_data[i] = qa_data[i] + tuple(pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({928,\n",
       "  3996,\n",
       "  4958,\n",
       "  10627,\n",
       "  10998,\n",
       "  12541,\n",
       "  15816,\n",
       "  41365,\n",
       "  74204,\n",
       "  79152,\n",
       "  80083,\n",
       "  195118,\n",
       "  380952,\n",
       "  387476},\n",
       " {172893},\n",
       " '[MASK] is used to describe a chemical released by an animal that affects the behavior or physiology of animals of the same species.[SEP] pheromone.',\n",
       " 'hormone',\n",
       " 'enzyme',\n",
       " 'antibody',\n",
       " 'protease',\n",
       " 'neurotransmitter',\n",
       " 'toxin',\n",
       " 'antioxidant',\n",
       " 'catalyst',\n",
       " 'carbohydrate',\n",
       " 'lipid',\n",
       " 'chemical',\n",
       " 'animal',\n",
       " 'cocaine',\n",
       " 'predator',\n",
       " 'pain',\n",
       " 'taste',\n",
       " 'drug',\n",
       " 'light',\n",
       " 'fish',\n",
       " 'physiology')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(qa_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concepts_to_adj_matrices_2hop_all_pair__use_LM__Part1(data):\n",
    "    qc_ids = data[0]\n",
    "    ac_ids = data[1]\n",
    "    question = data[2]\n",
    "    distractors_set = data[3:]\n",
    "    extra_nodes = []\n",
    "    for distractor in distractors_set:\n",
    "        if distractor in concept2id:\n",
    "            extra_nodes_ids = concept2id[distractor] \n",
    "            extra_nodes.append(extra_nodes_ids)\n",
    "    return (sorted(qc_ids), sorted(ac_ids), question, extra_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [00:00<00:00, 96143.44it/s]\n"
     ]
    }
   ],
   "source": [
    "res1 = list(tqdm(map(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part1, qa_data), total=len(qa_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([928,\n",
       "  3996,\n",
       "  4958,\n",
       "  10627,\n",
       "  10998,\n",
       "  12541,\n",
       "  15816,\n",
       "  41365,\n",
       "  74204,\n",
       "  79152,\n",
       "  80083,\n",
       "  195118,\n",
       "  380952,\n",
       "  387476],\n",
       " [172893],\n",
       " '[MASK] is used to describe a chemical released by an animal that affects the behavior or physiology of animals of the same species.[SEP] pheromone.',\n",
       " [82112,\n",
       "  80002,\n",
       "  86218,\n",
       "  179716,\n",
       "  81011,\n",
       "  52322,\n",
       "  1152,\n",
       "  2968,\n",
       "  75321,\n",
       "  150169,\n",
       "  74204,\n",
       "  928,\n",
       "  68455,\n",
       "  48142,\n",
       "  12382,\n",
       "  13342,\n",
       "  20985,\n",
       "  4519,\n",
       "  2256,\n",
       "  80083])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考慮 全部的組合\n",
    "def concepts2adj(node_ids):\n",
    "    global id2relation\n",
    "    cids = np.array(node_ids, dtype=np.int32)\n",
    "    n_rel = len(id2relation)\n",
    "    n_node = cids.shape[0]\n",
    "    adj = np.zeros((n_rel, n_node, n_node), dtype=np.uint8)\n",
    "    triplets = []\n",
    "    for s in range(n_node):\n",
    "        for t in range(n_node):\n",
    "            s_c, t_c = cids[s], cids[t]\n",
    "            if cpnet.has_edge(s_c, t_c):\n",
    "                for e_attr in cpnet[s_c][t_c].values():\n",
    "                    if e_attr['rel'] >= 0 and e_attr['rel'] < n_rel:\n",
    "                        triplets.append([int(e_attr['rel']), int(s_c), int(t_c), e_attr['weight']])\n",
    "                        adj[e_attr['rel']][s][t] = 1\n",
    "    # cids += 1  # note!!! index 0 is reserved for padding\n",
    "    adj = coo_matrix(adj.reshape(-1, n_node))\n",
    "    return adj, cids, triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3(data):\n",
    "    qc_ids, ac_ids, question, extra_nodes = data\n",
    "    # schema_graph = qc_ids + ac_ids + extra_nodes # <== 考慮全部的組合\n",
    "    schema_graph = qc_ids + extra_nodes # <== 考慮 qc_ids 跟 extra_nodes 的組合 (without_ans)\n",
    "    adj, concepts, triplets = concepts2adj(schema_graph)\n",
    "    return {'triplets': triplets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [00:00<00:00, 757.15it/s]\n"
     ]
    }
   ],
   "source": [
    "res3 = list(tqdm(map(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3, res1), total=len(res1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 928, 12541, 1.0],\n",
       " [15, 928, 79152, 0.755],\n",
       " [13, 928, 12382, 2.0],\n",
       " [15, 928, 2256, 1.0],\n",
       " [15, 10998, 20985, 1.0],\n",
       " [15, 12541, 928, 1.0],\n",
       " [15, 12541, 928, 1.0],\n",
       " [15, 15816, 10998, 2.0],\n",
       " [15, 74204, 20985, 1.0],\n",
       " [15, 79152, 195118, 1.0],\n",
       " [15, 387476, 41365, 1.0],\n",
       " [5, 80002, 2968, 2.0],\n",
       " [5, 179716, 80002, 2.0],\n",
       " [15, 179716, 80002, 1.0],\n",
       " [15, 2968, 74204, 1.0],\n",
       " [15, 2968, 80002, 1.0],\n",
       " [15, 2968, 74204, 1.0],\n",
       " [15, 75321, 928, 1.0],\n",
       " [15, 75321, 928, 1.0],\n",
       " [15, 74204, 20985, 1.0],\n",
       " [15, 928, 12541, 1.0],\n",
       " [15, 928, 79152, 0.755],\n",
       " [13, 928, 12382, 2.0],\n",
       " [15, 928, 2256, 1.0],\n",
       " [5, 68455, 74204, 2.0],\n",
       " [5, 68455, 74204, 2.0],\n",
       " [5, 68455, 20985, 0.5],\n",
       " [5, 48142, 928, 2.0],\n",
       " [15, 48142, 928, 1.0],\n",
       " [5, 48142, 928, 2.0],\n",
       " [15, 48142, 928, 1.0],\n",
       " [15, 13342, 10998, 0.761],\n",
       " [15, 13342, 74204, 1.0],\n",
       " [15, 13342, 74204, 1.0],\n",
       " [7, 20985, 10998, 2.0],\n",
       " [5, 20985, 74204, 2.0],\n",
       " [15, 20985, 74204, 0.189],\n",
       " [5, 20985, 74204, 2.0],\n",
       " [15, 20985, 74204, 0.189],\n",
       " [15, 20985, 68455, 0.204],\n",
       " [5, 2256, 928, 4.472],\n",
       " [15, 2256, 928, 8.938],\n",
       " [5, 2256, 12541, 1.0],\n",
       " [15, 2256, 12541, 1.102],\n",
       " [15, 2256, 79152, 0.315],\n",
       " [5, 2256, 928, 4.472],\n",
       " [15, 2256, 928, 8.938]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3[0]['triplets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [00:00<00:00, 40906.94it/s]\n"
     ]
    }
   ],
   "source": [
    "res4 = []\n",
    "\n",
    "for item in tqdm(res3):\n",
    "    temp_list = []\n",
    "    for triplets in item['triplets']:\n",
    "        rel, source_node, target_node, weight = triplets\n",
    "        relation = id2relation[rel]\n",
    "        source = id2concept[source_node]\n",
    "        target = id2concept[target_node]\n",
    "        temp_list.append([relation, source, target, weight])\n",
    "    res4.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relatedto', 'animal', 'animals', 1.0],\n",
       " ['relatedto', 'animal', 'species', 0.755],\n",
       " ['notdesires', 'animal', 'pain', 2.0],\n",
       " ['relatedto', 'animal', 'fish', 1.0],\n",
       " ['relatedto', 'use', 'drug', 1.0],\n",
       " ['relatedto', 'animals', 'animal', 1.0],\n",
       " ['relatedto', 'animals', 'animal', 1.0],\n",
       " ['relatedto', 'used', 'use', 2.0],\n",
       " ['relatedto', 'chemical', 'drug', 1.0],\n",
       " ['relatedto', 'species', 'specie', 1.0],\n",
       " ['relatedto', 'affects', 'affect', 1.0],\n",
       " ['isa', 'enzyme', 'catalyst', 2.0],\n",
       " ['isa', 'protease', 'enzyme', 2.0],\n",
       " ['relatedto', 'protease', 'enzyme', 1.0],\n",
       " ['relatedto', 'catalyst', 'chemical', 1.0],\n",
       " ['relatedto', 'catalyst', 'enzyme', 1.0],\n",
       " ['relatedto', 'catalyst', 'chemical', 1.0],\n",
       " ['relatedto', 'carbohydrate', 'animal', 1.0],\n",
       " ['relatedto', 'carbohydrate', 'animal', 1.0],\n",
       " ['relatedto', 'chemical', 'drug', 1.0],\n",
       " ['relatedto', 'animal', 'animals', 1.0],\n",
       " ['relatedto', 'animal', 'species', 0.755],\n",
       " ['notdesires', 'animal', 'pain', 2.0],\n",
       " ['relatedto', 'animal', 'fish', 1.0],\n",
       " ['isa', 'cocaine', 'chemical', 2.0],\n",
       " ['isa', 'cocaine', 'chemical', 2.0],\n",
       " ['isa', 'cocaine', 'drug', 0.5],\n",
       " ['isa', 'predator', 'animal', 2.0],\n",
       " ['relatedto', 'predator', 'animal', 1.0],\n",
       " ['isa', 'predator', 'animal', 2.0],\n",
       " ['relatedto', 'predator', 'animal', 1.0],\n",
       " ['relatedto', 'taste', 'use', 0.761],\n",
       " ['relatedto', 'taste', 'chemical', 1.0],\n",
       " ['relatedto', 'taste', 'chemical', 1.0],\n",
       " ['hassubevent', 'drug', 'use', 2.0],\n",
       " ['isa', 'drug', 'chemical', 2.0],\n",
       " ['relatedto', 'drug', 'chemical', 0.189],\n",
       " ['isa', 'drug', 'chemical', 2.0],\n",
       " ['relatedto', 'drug', 'chemical', 0.189],\n",
       " ['relatedto', 'drug', 'cocaine', 0.204],\n",
       " ['isa', 'fish', 'animal', 4.472],\n",
       " ['relatedto', 'fish', 'animal', 8.938],\n",
       " ['isa', 'fish', 'animals', 1.0],\n",
       " ['relatedto', 'fish', 'animals', 1.102],\n",
       " ['relatedto', 'fish', 'species', 0.315],\n",
       " ['isa', 'fish', 'animal', 4.472],\n",
       " ['relatedto', 'fish', 'animal', 8.938]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'augmentation/chatgpt_mlm_test_triplet(without_ans).json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved to augmentation/chatgpt_mlm_test_triplet(without_ans).json\n"
     ]
    }
   ],
   "source": [
    "with open(output_path, 'w') as fout:\n",
    "    json.dump(res4, fout)\n",
    "print(f'data saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation =  relatedto\n",
      "source_node =  animal\n",
      "target_node =  animals\n",
      "weight =  1.0\n"
     ]
    }
   ],
   "source": [
    "rel, source_node, target_node, weight = res3[0]['triplets'][0]\n",
    "print('relation = ',id2relation[rel])\n",
    "print('source_node = ',id2concept[source_node])\n",
    "print('target_node = ',id2concept[target_node])\n",
    "print('weight = ',weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
